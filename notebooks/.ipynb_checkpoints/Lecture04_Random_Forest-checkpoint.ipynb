{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92036db1",
   "metadata": {},
   "source": [
    "# Lecture 04 Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c7c4e",
   "metadata": {},
   "source": [
    "Below is a simplified example of how to implement a basic version of a Random Forest from scratch in Python. This example focuses on core concepts such as bootstrapping, decision tree creation, and majority voting.\n",
    "\n",
    "We'll make the following assumptions:\n",
    "- The trees will be simple decision stumps (trees with a depth of 1).\n",
    "- We'll bootstrap the data for each tree.\n",
    "- We'll use majority voting for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d46c23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [ 1  1 -1 -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Decision Tree Class\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_features=None):\n",
    "        self.max_features = max_features\n",
    "        self.split_feature = None\n",
    "        self.split_value = None\n",
    "        self.left_prediction = None\n",
    "        self.right_prediction = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        # Select random subset of features\n",
    "        feature_indices = np.random.choice(n_features, self.max_features, replace=False)\n",
    "        best_gini = float(\"inf\")\n",
    "\n",
    "        # Find the best split\n",
    "        for feature in feature_indices:\n",
    "            values = X[:, feature]\n",
    "            thresholds = np.unique(values)\n",
    "            for threshold in thresholds:\n",
    "                left_mask = values < threshold\n",
    "                right_mask = ~left_mask\n",
    "                gini = self._gini_impurity(y[left_mask], y[right_mask])\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    self.split_feature = feature\n",
    "                    self.split_value = threshold\n",
    "                    self.left_prediction = self._majority_vote(y[left_mask])\n",
    "                    self.right_prediction = self._majority_vote(y[right_mask])\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for row in X:\n",
    "            if row[self.split_feature] < self.split_value:\n",
    "                predictions.append(self.left_prediction)\n",
    "            else:\n",
    "                predictions.append(self.right_prediction)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _gini_impurity(self, left, right):\n",
    "        n = len(left) + len(right)\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        left_score = 1.0 - sum((np.sum(left == c) / len(left)) ** 2 for c in np.unique(left))\n",
    "        right_score = 1.0 - sum((np.sum(right == c) / len(right)) ** 2 for c in np.unique(right))\n",
    "        return (len(left) * left_score + len(right) * right_score) / n\n",
    "\n",
    "    def _majority_vote(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "# Random Forest Class\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=10, max_features=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Bootstrap sampling\n",
    "            sample_indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            X_sample, y_sample = X[sample_indices], y[sample_indices]\n",
    "            # Train a decision tree\n",
    "            tree = DecisionTree(max_features=self.max_features)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Aggregate predictions from all trees\n",
    "        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        # Majority voting\n",
    "        final_predictions = np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=0, arr=tree_predictions)\n",
    "        return final_predictions\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Simple example data: [Open Close High, Low]\n",
    "    X = np.array([[101.2, 102.1, 102.5, 100.9], [102.2, 103.1, 103.5, 102.2], \n",
    "                  [103.2, 102.4, 103.5, 102.2], [104.5, 103.5, 104.75, 102.5], \n",
    "                  [104.5, 106.5, 106.9, 103.7], [106.2, 107.8, 108.2, 106.1]])\n",
    "    y = np.array([1, 1, -1, -1, 1, 1])\n",
    "\n",
    "    # Instantiate and train the random forest\n",
    "    clf = RandomForest(n_estimators=5, max_features=2)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Predictions\n",
    "    predictions = clf.predict(X)\n",
    "    print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b091ad",
   "metadata": {},
   "source": [
    "Key Steps:\n",
    "- Decision Stump: This is a simple classifier that looks for a single best feature and threshold to split the data.\n",
    "- Random Forest: This class builds multiple decision stumps (trees with depth 1), bootstraps the data, and aggregates the results from all trees using majority voting.\n",
    "\n",
    "This code is quite basic and can be extended to include more sophisticated decision trees, hyperparameters, and splitting criteria. For instance:\n",
    "- You can replace DecisionStump with a more advanced DecisionTree class.\n",
    "- You can add criteria such as Gini impurity for feature selection and threshold splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf025fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
